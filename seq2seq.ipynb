{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take some RNN models from tensorflow seq2seq:\n",
    "\n",
    "TODO:\n",
    "\n",
    "- [x] For test data, show input batch words, output words, and predicted words (and print this to a file every so often)\n",
    "\n",
    "- [x] Switch to `embedding_rnn_seq2seq` model\n",
    "\n",
    "- [x] Capture word embeddings\n",
    "\n",
    "- Implement VAE and capture z's to plot in next step\n",
    "\n",
    "- Visualize latent space for VAE\n",
    "\n",
    "- [x] Get good summaries of Error, etc written to files during training\n",
    "\n",
    "- Any more finishing of model using original en -> fr data. Such as saving the tensorboard graph model.\n",
    "\n",
    "Figures:\n",
    "\n",
    "1. model diagram\n",
    "2. Training curves\n",
    "3. token embeddings\n",
    "4. visualize latent (color by sequence families or GO category)\n",
    "5. reconstruction (multiple seq alignment)\n",
    "\n",
    "## Now simply apply to protein data\n",
    "\n",
    "- Run protein data through the system using same tokenization machinery as for en -> fr translation\n",
    "\n",
    "- Have to change bucket sizes appropriatly\n",
    "\n",
    "- Tokenize 2 amino acids to get 400 total combos because easier to analyze embeddings. See if order matters ie does XY = YX ?\n",
    "\n",
    "- Color latent space by sequence attributes\n",
    "\n",
    "## (Maybe) do the same thing, but for protein structure \n",
    "\n",
    "- (going to require more work since no longer dealing with discrete tokens)\n",
    "\n",
    "- Have to encode real valued positions, orientations etc ......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Library for creating sequence-to-sequence models in TensorFlow.\n",
    "\n",
    "Sequence-to-sequence recurrent neural networks can learn complex functions\n",
    "that map input sequences to output sequences. These models yield very good\n",
    "results on a number of tasks, such as speech recognition, parsing, machine\n",
    "translation, or even constructing automated replies to emails.\n",
    "\n",
    "Before using this module, it is recommended to read the TensorFlow tutorial\n",
    "on sequence-to-sequence models. It explains the basic concepts of this module\n",
    "and shows an end-to-end example of how to build a translation model.\n",
    "  https://www.tensorflow.org/versions/master/tutorials/seq2seq/index.html\n",
    "\n",
    "Here is an overview of functions available in this module. They all use\n",
    "a very similar interface, so after reading the above tutorial and using\n",
    "one of them, others should be easy to substitute.\n",
    "\n",
    "* Full sequence-to-sequence models.\n",
    "  - basic_rnn_seq2seq: The most basic RNN-RNN model.\n",
    "  - tied_rnn_seq2seq: The basic model with tied encoder and decoder weights.\n",
    "  - embedding_rnn_seq2seq: The basic model with input embedding.\n",
    "  - embedding_tied_rnn_seq2seq: The tied model with input embedding.\n",
    "  - embedding_attention_seq2seq: Advanced model with input embedding and\n",
    "      the neural attention mechanism; recommended for complex tasks.\n",
    "\n",
    "* Multi-task sequence-to-sequence models.\n",
    "  - one2many_rnn_seq2seq: The embedding model with multiple decoders.\n",
    "\n",
    "* Decoders (when you write your own encoder, you can use these to decode;\n",
    "    e.g., if you want to write a model that generates captions for images).\n",
    "  - rnn_decoder: The basic decoder based on a pure RNN.\n",
    "  - attention_decoder: A decoder that uses the attention mechanism.\n",
    "\n",
    "* Losses.\n",
    "  - sequence_loss: Loss for a sequence model returning average log-perplexity.\n",
    "  - sequence_loss_by_example: As above, but not averaging over all examples.\n",
    "\n",
    "* model_with_buckets: A convenience function to create models with bucketing\n",
    "    (see the tutorial above for an explanation of why and how to use it).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# We disable pylint because we need python3 compatibility.\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "from six.moves import zip     # pylint: disable=redefined-builtin\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import embedding_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import rnn\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import variable_scope\n",
    "from tensorflow.python.util import nest\n",
    "\n",
    "from seq2seq import sequence_loss, embedding_rnn_decoder\n",
    "\n",
    "def model_with_buckets(encoder_inputs, decoder_inputs, targets, weights,\n",
    "                       buckets, seq2seq, softmax_loss_function=None,\n",
    "                       per_example_loss=False, name=None):\n",
    "  \"\"\"Create a sequence-to-sequence model with support for bucketing.\n",
    "\n",
    "  The seq2seq argument is a function that defines a sequence-to-sequence model,\n",
    "  e.g., seq2seq = lambda x, y: basic_rnn_seq2seq(x, y, rnn_cell.GRUCell(24))\n",
    "\n",
    "  Args:\n",
    "    encoder_inputs: A list of Tensors to feed the encoder; first seq2seq input.\n",
    "    decoder_inputs: A list of Tensors to feed the decoder; second seq2seq input.\n",
    "    targets: A list of 1D batch-sized int32 Tensors (desired output sequence).\n",
    "    weights: List of 1D batch-sized float-Tensors to weight the targets.\n",
    "    buckets: A list of pairs of (input size, output size) for each bucket.\n",
    "    seq2seq: A sequence-to-sequence model function; it takes 2 input that\n",
    "      agree with encoder_inputs and decoder_inputs, and returns a pair\n",
    "      consisting of outputs and states (as, e.g., basic_rnn_seq2seq).\n",
    "    softmax_loss_function: Function (inputs-batch, labels-batch) -> loss-batch\n",
    "      to be used instead of the standard softmax (the default if this is None).\n",
    "    per_example_loss: Boolean. If set, the returned loss will be a batch-sized\n",
    "      tensor of losses for each sequence in the batch. If unset, it will be\n",
    "      a scalar with the averaged loss from all examples.\n",
    "    name: Optional name for this operation, defaults to \"model_with_buckets\".\n",
    "\n",
    "  Returns:\n",
    "    A tuple of the form (outputs, losses), where:\n",
    "      outputs: The outputs for each bucket. Its j'th element consists of a list\n",
    "        of 2D Tensors of shape [batch_size x num_decoder_symbols] (jth outputs).\n",
    "      losses: List of scalar Tensors, representing losses for each bucket, or,\n",
    "        if per_example_loss is set, a list of 1D batch-sized float Tensors.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If length of encoder_inputsut, targets, or weights is smaller\n",
    "      than the largest (last) bucket.\n",
    "  \"\"\"\n",
    "  if len(encoder_inputs) < buckets[-1][0]:\n",
    "    raise ValueError(\"Length of encoder_inputs (%d) must be at least that of la\"\n",
    "                     \"st bucket (%d).\" % (len(encoder_inputs), buckets[-1][0]))\n",
    "  if len(targets) < buckets[-1][1]:\n",
    "    raise ValueError(\"Length of targets (%d) must be at least that of last\"\n",
    "                     \"bucket (%d).\" % (len(targets), buckets[-1][1]))\n",
    "  if len(weights) < buckets[-1][1]:\n",
    "    raise ValueError(\"Length of weights (%d) must be at least that of last\"\n",
    "                     \"bucket (%d).\" % (len(weights), buckets[-1][1]))\n",
    "\n",
    "  all_inputs = encoder_inputs + decoder_inputs + targets + weights\n",
    "  losses = []\n",
    "  outputs = []\n",
    "  with ops.op_scope(all_inputs, name, \"model_with_buckets\"):\n",
    "    for j, bucket in enumerate(buckets):\n",
    "      with variable_scope.variable_scope(variable_scope.get_variable_scope(),\n",
    "                                         reuse=True if j > 0 else None):\n",
    "        bucket_outputs, _ = seq2seq(encoder_inputs[:bucket[0]],\n",
    "                                    decoder_inputs[:bucket[1]])\n",
    "        outputs.append(bucket_outputs)\n",
    "        if per_example_loss:\n",
    "          losses.append(sequence_loss_by_example(\n",
    "              outputs[-1], targets[:bucket[1]], weights[:bucket[1]],\n",
    "              softmax_loss_function=softmax_loss_function))\n",
    "        else:\n",
    "          losses.append(sequence_loss(\n",
    "              outputs[-1], targets[:bucket[1]], weights[:bucket[1]],\n",
    "              softmax_loss_function=softmax_loss_function))\n",
    "\n",
    "  return outputs, losses\n",
    "\n",
    "def embedding_rnn_seq2seq(encoder_inputs, decoder_inputs, cell,\n",
    "                          num_encoder_symbols, num_decoder_symbols,\n",
    "                          embedding_size, output_projection=None,\n",
    "                          feed_previous=False, dtype=dtypes.float32,\n",
    "                          scope=None):\n",
    "  \"\"\"Embedding RNN sequence-to-sequence model.\n",
    "\n",
    "  This model first embeds encoder_inputs by a newly created embedding (of shape\n",
    "  [num_encoder_symbols x input_size]). Then it runs an RNN to encode\n",
    "  embedded encoder_inputs into a state vector. Next, it embeds decoder_inputs\n",
    "  by another newly created embedding (of shape [num_decoder_symbols x\n",
    "  input_size]). Then it runs RNN decoder, initialized with the last\n",
    "  encoder state, on embedded decoder_inputs.\n",
    "\n",
    "  Args:\n",
    "    encoder_inputs: A list of 1D int32 Tensors of shape [batch_size].\n",
    "    decoder_inputs: A list of 1D int32 Tensors of shape [batch_size].\n",
    "    cell: rnn_cell.RNNCell defining the cell function and size.\n",
    "    num_encoder_symbols: Integer; number of symbols on the encoder side.\n",
    "    num_decoder_symbols: Integer; number of symbols on the decoder side.\n",
    "    embedding_size: Integer, the length of the embedding vector for each symbol.\n",
    "    output_projection: None or a pair (W, B) of output projection weights and\n",
    "      biases; W has shape [output_size x num_decoder_symbols] and B has\n",
    "      shape [num_decoder_symbols]; if provided and feed_previous=True, each\n",
    "      fed previous output will first be multiplied by W and added B.\n",
    "    feed_previous: Boolean or scalar Boolean Tensor; if True, only the first\n",
    "      of decoder_inputs will be used (the \"GO\" symbol), and all other decoder\n",
    "      inputs will be taken from previous outputs (as in embedding_rnn_decoder).\n",
    "      If False, decoder_inputs are used as given (the standard decoder case).\n",
    "    dtype: The dtype of the initial state for both the encoder and encoder\n",
    "      rnn cells (default: tf.float32).\n",
    "    scope: VariableScope for the created subgraph; defaults to\n",
    "      \"embedding_rnn_seq2seq\"\n",
    "\n",
    "  Returns:\n",
    "    A tuple of the form (outputs, state), where:\n",
    "      outputs: A list of the same length as decoder_inputs of 2D Tensors with\n",
    "        shape [batch_size x num_decoder_symbols] containing the generated\n",
    "        outputs.\n",
    "      state: The state of each decoder cell in each time-step. This is a list\n",
    "        with length len(decoder_inputs) -- one item for each time-step.\n",
    "        It is a 2D Tensor of shape [batch_size x cell.state_size].\n",
    "  \"\"\"\n",
    "  with variable_scope.variable_scope(scope or \"embedding_rnn_seq2seq\"):\n",
    "    # Encoder.\n",
    "    encoder_cell = rnn_cell.EmbeddingWrapper(\n",
    "        cell, embedding_classes=num_encoder_symbols,\n",
    "        embedding_size=embedding_size)\n",
    "    _, encoder_state = rnn.rnn(encoder_cell, encoder_inputs, dtype=dtype)\n",
    "    \n",
    "    # Patrick: keep your eyes on that encoder state\n",
    "\n",
    "    # Decoder.\n",
    "    if output_projection is None:\n",
    "      cell = rnn_cell.OutputProjectionWrapper(cell, num_decoder_symbols)\n",
    "\n",
    "    if isinstance(feed_previous, bool):\n",
    "      return embedding_rnn_decoder(\n",
    "          decoder_inputs, encoder_state, cell, num_decoder_symbols,\n",
    "          embedding_size, output_projection=output_projection,\n",
    "          feed_previous=feed_previous)\n",
    "\n",
    "    # If feed_previous is a Tensor, we construct 2 graphs and use cond.\n",
    "    def decoder(feed_previous_bool):\n",
    "      reuse = None if feed_previous_bool else True\n",
    "      with variable_scope.variable_scope(variable_scope.get_variable_scope(),\n",
    "                                         reuse=reuse):\n",
    "        outputs, state = embedding_rnn_decoder(\n",
    "            decoder_inputs, encoder_state, cell, num_decoder_symbols,\n",
    "            embedding_size, output_projection=output_projection,\n",
    "            feed_previous=feed_previous_bool,\n",
    "            update_embedding_for_previous=False)\n",
    "        state_list = [state]\n",
    "        if nest.is_sequence(state):\n",
    "          state_list = nest.flatten(state)\n",
    "        return outputs + state_list\n",
    "\n",
    "    outputs_and_state = control_flow_ops.cond(feed_previous,\n",
    "                                              lambda: decoder(True),\n",
    "                                              lambda: decoder(False))\n",
    "    outputs_len = len(decoder_inputs)  # Outputs length same as decoder inputs.\n",
    "    state_list = outputs_and_state[outputs_len:]\n",
    "    state = state_list[0]\n",
    "    if nest.is_sequence(encoder_state):\n",
    "      state = nest.pack_sequence_as(structure=encoder_state,\n",
    "                                    flat_sequence=state_list)\n",
    "    return outputs_and_state[:outputs_len], state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The translation model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Sequence-to-sequence model with an attention mechanism.\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import data_utils\n",
    "\n",
    "\n",
    "class Seq2SeqModel(object):\n",
    "  \"\"\"Sequence-to-sequence model with attention and for multiple buckets.\n",
    "\n",
    "  This class implements a multi-layer recurrent neural network as encoder,\n",
    "  and an attention-based decoder. This is the same as the model described in\n",
    "  this paper: http://arxiv.org/abs/1412.7449 - please look there for details,\n",
    "  or into the seq2seq library for complete model implementation.\n",
    "  This class also allows to use GRU cells in addition to LSTM cells, and\n",
    "  sampled softmax to handle large output vocabulary size. A single-layer\n",
    "  version of this model, but with bi-directional encoder, was presented in\n",
    "    http://arxiv.org/abs/1409.0473\n",
    "  and sampled softmax is described in Section 3 of the following paper.\n",
    "    http://arxiv.org/abs/1412.2007\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               source_vocab_size,\n",
    "               target_vocab_size,\n",
    "               buckets,\n",
    "               size,\n",
    "               num_layers,\n",
    "               max_gradient_norm,\n",
    "               batch_size,\n",
    "               learning_rate,\n",
    "               learning_rate_decay_factor,\n",
    "               use_lstm=False,\n",
    "               num_samples=512,\n",
    "               forward_only=False,\n",
    "               dtype=tf.float32):\n",
    "    \"\"\"Create the model.\n",
    "\n",
    "    Args:\n",
    "      source_vocab_size: size of the source vocabulary.\n",
    "      target_vocab_size: size of the target vocabulary.\n",
    "      buckets: a list of pairs (I, O), where I specifies maximum input length\n",
    "        that will be processed in that bucket, and O specifies maximum output\n",
    "        length. Training instances that have inputs longer than I or outputs\n",
    "        longer than O will be pushed to the next bucket and padded accordingly.\n",
    "        We assume that the list is sorted, e.g., [(2, 4), (8, 16)].\n",
    "      size: number of units in each layer of the model.\n",
    "      num_layers: number of layers in the model.\n",
    "      max_gradient_norm: gradients will be clipped to maximally this norm.\n",
    "      batch_size: the size of the batches used during training;\n",
    "        the model construction is independent of batch_size, so it can be\n",
    "        changed after initialization if this is convenient, e.g., for decoding.\n",
    "      learning_rate: learning rate to start with.\n",
    "      learning_rate_decay_factor: decay learning rate by this much when needed.\n",
    "      use_lstm: if true, we use LSTM cells instead of GRU cells.\n",
    "      num_samples: number of samples for sampled softmax.\n",
    "      forward_only: if set, we do not construct the backward pass in the model.\n",
    "      dtype: the data type to use to store internal variables.\n",
    "    \"\"\"\n",
    "    self.source_vocab_size = source_vocab_size\n",
    "    self.target_vocab_size = target_vocab_size\n",
    "    self.buckets = buckets\n",
    "    self.batch_size = batch_size\n",
    "    self.learning_rate = tf.Variable(\n",
    "        float(learning_rate), trainable=False, dtype=dtype)\n",
    "    self.learning_rate_decay_op = self.learning_rate.assign(\n",
    "        self.learning_rate * learning_rate_decay_factor)\n",
    "    self.global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # If we use sampled softmax, we need an output projection.\n",
    "    output_projection = None\n",
    "    softmax_loss_function = None\n",
    "    # Sampled softmax only makes sense if we sample less than vocabulary size.\n",
    "    if num_samples > 0 and num_samples < self.target_vocab_size:\n",
    "      w_t = tf.get_variable(\"proj_w\", [self.target_vocab_size, size], dtype=dtype)\n",
    "      w = tf.transpose(w_t)\n",
    "      b = tf.get_variable(\"proj_b\", [self.target_vocab_size], dtype=dtype)\n",
    "      output_projection = (w, b)\n",
    "\n",
    "      def sampled_loss(inputs, labels):\n",
    "        labels = tf.reshape(labels, [-1, 1])\n",
    "        # We need to compute the sampled_softmax_loss using 32bit floats to\n",
    "        # avoid numerical instabilities.\n",
    "        local_w_t = tf.cast(w_t, tf.float32)\n",
    "        local_b = tf.cast(b, tf.float32)\n",
    "        local_inputs = tf.cast(inputs, tf.float32)\n",
    "        return tf.cast(\n",
    "            tf.nn.sampled_softmax_loss(local_w_t, local_b, local_inputs, labels,\n",
    "                                       num_samples, self.target_vocab_size),\n",
    "            dtype)\n",
    "      softmax_loss_function = sampled_loss\n",
    "\n",
    "    # Create the internal multi-layer cell for our RNN.\n",
    "    single_cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "    if use_lstm:\n",
    "      single_cell = tf.nn.rnn_cell.BasicLSTMCell(size)\n",
    "    cell = single_cell\n",
    "    if num_layers > 1:\n",
    "      cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\n",
    "\n",
    "    # The seq2seq function: we use embedding for the input and attention.\n",
    "    def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n",
    "      return embedding_rnn_seq2seq(\n",
    "          encoder_inputs,\n",
    "          decoder_inputs,\n",
    "          cell,\n",
    "          num_encoder_symbols=source_vocab_size,\n",
    "          num_decoder_symbols=target_vocab_size,\n",
    "          embedding_size=size,\n",
    "          output_projection=output_projection,\n",
    "          feed_previous=do_decode,\n",
    "          dtype=dtype)\n",
    "\n",
    "    # Feeds for inputs.\n",
    "    self.encoder_inputs = []\n",
    "    self.decoder_inputs = []\n",
    "    self.target_weights = []\n",
    "    for i in range(buckets[-1][0]):  # Last bucket is the biggest one.\n",
    "      self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n",
    "                                                name=\"encoder{0}\".format(i)))\n",
    "    for i in range(buckets[-1][1] + 1):\n",
    "      self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n",
    "                                                name=\"decoder{0}\".format(i)))\n",
    "      self.target_weights.append(tf.placeholder(dtype, shape=[None],\n",
    "                                                name=\"weight{0}\".format(i)))\n",
    "\n",
    "    # Our targets are decoder inputs shifted by one.\n",
    "    targets = [self.decoder_inputs[i + 1]\n",
    "               for i in range(len(self.decoder_inputs) - 1)]\n",
    "\n",
    "    # Training outputs and losses.\n",
    "    if forward_only:\n",
    "      self.outputs, self.losses = model_with_buckets(\n",
    "          self.encoder_inputs, self.decoder_inputs, targets,\n",
    "          self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),\n",
    "          softmax_loss_function=softmax_loss_function)\n",
    "      # If we use output projection, we need to project outputs for decoding.\n",
    "      if output_projection is not None:\n",
    "        for b in range(len(buckets)):\n",
    "          self.outputs[b] = [\n",
    "              tf.matmul(output, output_projection[0]) + output_projection[1]\n",
    "              for output in self.outputs[b]\n",
    "          ]\n",
    "    else:\n",
    "      self.outputs, self.losses = model_with_buckets(\n",
    "          self.encoder_inputs, self.decoder_inputs, targets,\n",
    "          self.target_weights, buckets,\n",
    "          lambda x, y: seq2seq_f(x, y, False),\n",
    "          softmax_loss_function=softmax_loss_function)\n",
    "\n",
    "    # Gradients and SGD update operation for training the model.\n",
    "    params = tf.trainable_variables()\n",
    "    if not forward_only:\n",
    "      self.gradient_norms = []\n",
    "      self.updates = []\n",
    "      opt = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "      for b in range(len(buckets)):\n",
    "        gradients = tf.gradients(self.losses[b], params)\n",
    "        clipped_gradients, norm = tf.clip_by_global_norm(gradients,\n",
    "                                                         max_gradient_norm)\n",
    "        self.gradient_norms.append(norm)\n",
    "        self.updates.append(opt.apply_gradients(\n",
    "            zip(clipped_gradients, params), global_step=self.global_step))\n",
    "\n",
    "    self.saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "  def step(self, session, encoder_inputs, decoder_inputs, target_weights,\n",
    "           bucket_id, forward_only):\n",
    "    \"\"\"Run a step of the model feeding the given inputs.\n",
    "\n",
    "    Args:\n",
    "      session: tensorflow session to use.\n",
    "      encoder_inputs: list of numpy int vectors to feed as encoder inputs.\n",
    "      decoder_inputs: list of numpy int vectors to feed as decoder inputs.\n",
    "      target_weights: list of numpy float vectors to feed as target weights.\n",
    "      bucket_id: which bucket of the model to use.\n",
    "      forward_only: whether to do the backward step or only forward.\n",
    "\n",
    "    Returns:\n",
    "      A triple consisting of gradient norm (or None if we did not do backward),\n",
    "      average perplexity, and the outputs.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: if length of encoder_inputs, decoder_inputs, or\n",
    "        target_weights disagrees with bucket size for the specified bucket_id.\n",
    "    \"\"\"\n",
    "    # Check if the sizes match.\n",
    "    encoder_size, decoder_size = self.buckets[bucket_id]\n",
    "    if len(encoder_inputs) != encoder_size:\n",
    "      raise ValueError(\"Encoder length must be equal to the one in bucket,\"\n",
    "                       \" %d != %d.\" % (len(encoder_inputs), encoder_size))\n",
    "    if len(decoder_inputs) != decoder_size:\n",
    "      raise ValueError(\"Decoder length must be equal to the one in bucket,\"\n",
    "                       \" %d != %d.\" % (len(decoder_inputs), decoder_size))\n",
    "    if len(target_weights) != decoder_size:\n",
    "      raise ValueError(\"Weights length must be equal to the one in bucket,\"\n",
    "                       \" %d != %d.\" % (len(target_weights), decoder_size))\n",
    "\n",
    "    # Input feed: encoder inputs, decoder inputs, target_weights, as provided.\n",
    "    input_feed = {}\n",
    "    for l in range(encoder_size):\n",
    "      input_feed[self.encoder_inputs[l].name] = encoder_inputs[l]\n",
    "    for l in range(decoder_size):\n",
    "      input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]\n",
    "      input_feed[self.target_weights[l].name] = target_weights[l]\n",
    "\n",
    "    # Since our targets are decoder inputs shifted by one, we need one more.\n",
    "    last_target = self.decoder_inputs[decoder_size].name\n",
    "    input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)\n",
    "\n",
    "    # Output feed: depends on whether we do a backward step or not.\n",
    "    if not forward_only:\n",
    "      output_feed = [self.updates[bucket_id],  # Update Op that does SGD.\n",
    "                     self.gradient_norms[bucket_id],  # Gradient norm.\n",
    "                     self.losses[bucket_id]]  # Loss for this batch.\n",
    "    else:\n",
    "      output_feed = [self.losses[bucket_id]]  # Loss for this batch.\n",
    "      for l in range(decoder_size):  # Output logits.\n",
    "        output_feed.append(self.outputs[bucket_id][l])\n",
    "\n",
    "    outputs = session.run(output_feed, input_feed)\n",
    "    if not forward_only:\n",
    "      return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n",
    "    else:\n",
    "      return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\n",
    "\n",
    "  def get_batch(self, data, bucket_id):\n",
    "    \"\"\"Get a random batch of data from the specified bucket, prepare for step.\n",
    "\n",
    "    To feed data in step(..) it must be a list of batch-major vectors, while\n",
    "    data here contains single length-major cases. So the main logic of this\n",
    "    function is to re-index data cases to be in the proper format for feeding.\n",
    "\n",
    "    Args:\n",
    "      data: a tuple of size len(self.buckets) in which each element contains\n",
    "        lists of pairs of input and output data that we use to create a batch.\n",
    "      bucket_id: integer, which bucket to get the batch for.\n",
    "\n",
    "    Returns:\n",
    "      The triple (encoder_inputs, decoder_inputs, target_weights) for\n",
    "      the constructed batch that has the proper format to call step(...) later.\n",
    "    \"\"\"\n",
    "    encoder_size, decoder_size = self.buckets[bucket_id]\n",
    "    encoder_inputs, decoder_inputs = [], []\n",
    "\n",
    "    # Get a random batch of encoder and decoder inputs from data,\n",
    "    # pad them if needed, reverse encoder inputs and add GO to decoder.\n",
    "    for _ in range(self.batch_size):\n",
    "      encoder_input, decoder_input = random.choice(data[bucket_id])\n",
    "\n",
    "      # Encoder inputs are padded and then reversed.\n",
    "      encoder_pad = [data_utils.PAD_ID] * (encoder_size - len(encoder_input))\n",
    "      encoder_inputs.append(list(reversed(encoder_input + encoder_pad)))\n",
    "\n",
    "      # Decoder inputs get an extra \"GO\" symbol, and are padded then.\n",
    "      decoder_pad_size = decoder_size - len(decoder_input) - 1\n",
    "      decoder_inputs.append([data_utils.GO_ID] + decoder_input +\n",
    "                            [data_utils.PAD_ID] * decoder_pad_size)\n",
    "\n",
    "    # Now we create batch-major vectors from the data selected above.\n",
    "    batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], []\n",
    "\n",
    "    # Batch encoder inputs are just re-indexed encoder_inputs.\n",
    "    for length_idx in range(encoder_size):\n",
    "      batch_encoder_inputs.append(\n",
    "          np.array([encoder_inputs[batch_idx][length_idx]\n",
    "                    for batch_idx in range(self.batch_size)], dtype=np.int32))\n",
    "\n",
    "    # Batch decoder inputs are re-indexed decoder_inputs, we create weights.\n",
    "    for length_idx in range(decoder_size):\n",
    "      batch_decoder_inputs.append(\n",
    "          np.array([decoder_inputs[batch_idx][length_idx]\n",
    "                    for batch_idx in range(self.batch_size)], dtype=np.int32))\n",
    "\n",
    "      # Create target_weights to be 0 for targets that are padding.\n",
    "      batch_weight = np.ones(self.batch_size, dtype=np.float32)\n",
    "      for batch_idx in range(self.batch_size):\n",
    "        # We set weight to 0 if the corresponding target is a PAD symbol.\n",
    "        # The corresponding target is decoder_input shifted by 1 forward.\n",
    "        if length_idx < decoder_size - 1:\n",
    "          target = decoder_inputs[batch_idx][length_idx + 1]\n",
    "        if length_idx == decoder_size - 1 or target == data_utils.PAD_ID:\n",
    "          batch_weight[batch_idx] = 0.0\n",
    "      batch_weights.append(batch_weight)\n",
    "    return batch_encoder_inputs, batch_decoder_inputs, batch_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing WMT data in seq2seq_data/\n",
      "Creating 2 layers of 512 units.\n",
      "Created model with fresh parameters.\n",
      "Reading development and training data (limit: 100000).\n",
      "  reading data line 100000\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Binary for training translation models and decoding from them.\n",
    "\n",
    "Running this program without --decode will download the WMT corpus into\n",
    "the directory specified as --data_dir and tokenize it in a very basic way,\n",
    "and then start training a model saving checkpoints to --train_dir.\n",
    "\n",
    "Running with --decode starts an interactive loop so you can see how\n",
    "the current checkpoint translates English sentences into French.\n",
    "\n",
    "See the following papers for more information on neural translation models.\n",
    " * http://arxiv.org/abs/1409.3215\n",
    " * http://arxiv.org/abs/1409.0473\n",
    " * http://arxiv.org/abs/1412.2007\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import data_utils\n",
    "\n",
    "learning_rate = 0.5\n",
    "learning_rate_decay_factor = 0.99\n",
    "max_gradient_norm = 5.0\n",
    "batch_size = 64\n",
    "size = 512 # both the embedding size and the RNN state size\n",
    "num_layers = 2\n",
    "en_vocab_size = 40000\n",
    "fr_vocab_size = 40000\n",
    "data_dir = \"seq2seq_data/\"\n",
    "train_dir = \"seq2seq_train/\"\n",
    "max_train_data_size = 100000\n",
    "steps_per_checkpoint = 2000\n",
    "do_decode = False\n",
    "do_self_test = False\n",
    "\n",
    "\n",
    "# We use a number of buckets and pad to the closest one for efficiency.\n",
    "# See Seq2SeqModel for details of how they work.\n",
    "_buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]\n",
    "\n",
    "\n",
    "def read_data(source_path, target_path, max_size=None):\n",
    "  \"\"\"Read data from source and target files and put into buckets.\n",
    "\n",
    "  Args:\n",
    "    source_path: path to the files with token-ids for the source language.\n",
    "    target_path: path to the file with token-ids for the target language;\n",
    "      it must be aligned with the source file: n-th line contains the desired\n",
    "      output for n-th line from the source_path.\n",
    "    max_size: maximum number of lines to read, all other will be ignored;\n",
    "      if 0 or None, data files will be read completely (no limit).\n",
    "\n",
    "  Returns:\n",
    "    data_set: a list of length len(_buckets); data_set[n] contains a list of\n",
    "      (source, target) pairs read from the provided data files that fit\n",
    "      into the n-th bucket, i.e., such that len(source) < _buckets[n][0] and\n",
    "      len(target) < _buckets[n][1]; source and target are lists of token-ids.\n",
    "  \"\"\"\n",
    "  data_set = [[] for _ in _buckets]\n",
    "  with tf.gfile.GFile(source_path, mode=\"r\") as source_file:\n",
    "    with tf.gfile.GFile(target_path, mode=\"r\") as target_file:\n",
    "      source, target = source_file.readline(), target_file.readline()\n",
    "      counter = 0\n",
    "      while source and target and (not max_size or counter < max_size):\n",
    "        counter += 1\n",
    "        if counter % 100000 == 0:\n",
    "          print(\"  reading data line %d\" % counter)\n",
    "          sys.stdout.flush()\n",
    "        source_ids = [int(x) for x in source.split()]\n",
    "        target_ids = [int(x) for x in target.split()]\n",
    "        target_ids.append(data_utils.EOS_ID)\n",
    "        for bucket_id, (source_size, target_size) in enumerate(_buckets):\n",
    "          if len(source_ids) < source_size and len(target_ids) < target_size:\n",
    "            data_set[bucket_id].append([source_ids, target_ids])\n",
    "            break\n",
    "        source, target = source_file.readline(), target_file.readline()\n",
    "  return data_set\n",
    "\n",
    "\n",
    "def create_model(session, forward_only):\n",
    "  \"\"\"Create translation model and initialize or load parameters in session.\"\"\"\n",
    "  model = Seq2SeqModel(\n",
    "      en_vocab_size,\n",
    "      fr_vocab_size,\n",
    "      _buckets,\n",
    "      size,\n",
    "      num_layers,\n",
    "      max_gradient_norm,\n",
    "      batch_size,\n",
    "      learning_rate,\n",
    "      learning_rate_decay_factor,\n",
    "      forward_only=forward_only)\n",
    "\n",
    "  ckpt = tf.train.get_checkpoint_state(train_dir)\n",
    "  if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n",
    "    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "    model.saver.restore(session, ckpt.model_checkpoint_path)\n",
    "  else:\n",
    "    print(\"Created model with fresh parameters.\")\n",
    "    session.run(tf.initialize_all_variables())\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "def decode():\n",
    "  with tf.Session() as sess:\n",
    "    # Create model and load parameters.\n",
    "    model = create_model(sess, True)\n",
    "    model.batch_size = 1  # We decode one sentence at a time.\n",
    "\n",
    "    # Load vocabularies.\n",
    "    en_vocab_path = os.path.join(data_dir, \"vocab%d.en\" % en_vocab_size)\n",
    "    fr_vocab_path = os.path.join(data_dir, \"vocab%d.fr\" % fr_vocab_size)\n",
    "    en_vocab, rev_en_vocab = data_utils.initialize_vocabulary(en_vocab_path)\n",
    "    fr_vocab, rev_fr_vocab = data_utils.initialize_vocabulary(fr_vocab_path)\n",
    "\n",
    "    # Decode from standard input.\n",
    "    sys.stdout.write(\"> \")\n",
    "    sys.stdout.flush()\n",
    "    sentence = sys.stdin.readline()\n",
    "    while sentence:\n",
    "      # Get token-ids for the input sentence.\n",
    "      token_ids = data_utils.sentence_to_token_ids(tf.compat.as_bytes(sentence), en_vocab)\n",
    "      # Which bucket does it belong to?\n",
    "      bucket_id = min([b for b in range(len(_buckets))\n",
    "                       if _buckets[b][0] > len(token_ids)])\n",
    "      # Get a 1-element batch to feed the sentence to the model.\n",
    "      encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n",
    "          {bucket_id: [(token_ids, [])]}, bucket_id)\n",
    "      # Get output logits for the sentence.\n",
    "      _, _, output_logits = model.step(sess, encoder_inputs, decoder_inputs,\n",
    "                                       target_weights, bucket_id, True)\n",
    "      # This is a greedy decoder - outputs are just argmaxes of output_logits.\n",
    "      outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n",
    "      # If there is an EOS symbol in outputs, cut them at that point.\n",
    "      if data_utils.EOS_ID in outputs:\n",
    "        outputs = outputs[:outputs.index(data_utils.EOS_ID)]\n",
    "      # Print out French sentence corresponding to outputs.\n",
    "      print(\" \".join([tf.compat.as_str(rev_fr_vocab[output]) for output in outputs]))\n",
    "      print(\"> \", end=\"\")\n",
    "      sys.stdout.flush()\n",
    "      sentence = sys.stdin.readline()\n",
    "\n",
    "\n",
    "def self_test():\n",
    "  \"\"\"Test the translation model.\"\"\"\n",
    "  with tf.Session() as sess: # make new session (no loading of saved session)\n",
    "    print(\"Self-test for neural translation model.\")\n",
    "    # Create model with vocabularies of 10, 2 small buckets, 2 layers of 32.\n",
    "    model = Seq2SeqModel(\n",
    "        10, # source vocab size\n",
    "        10, # target vocab size\n",
    "        [(3, 3),\n",
    "         (6, 6)], # buckets (max_en, max_fr)\n",
    "        1024, # size\n",
    "        2, # num layers\n",
    "        5.0, # max gradient norm\n",
    "        32, # batch size\n",
    "        0.3, # learning rate\n",
    "        0.99, # learning rate decay factor\n",
    "        use_lstm=False,\n",
    "        num_samples=8, # number of samples for sampled softmax\n",
    "        forward_only=False, # run 1-directional rnn (or something like that)\n",
    "        )\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    data_set = ([([1, 1], [2, 2]), ([3, 3], [4]), ([5], [6])],\n",
    "                [([1, 1, 1, 1, 1], [2, 2, 2, 2, 2]), ([3, 3, 3], [5, 6])])\n",
    "    for _ in range(10):  # Train the fake model for 5 steps.\n",
    "      bucket_id = random.choice([0, 1]) # choose a bucket\n",
    "      encoder_inputs, decoder_inputs, target_weights = model.get_batch(data_set, bucket_id)\n",
    "      _, step_loss, output_logits = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, False)\n",
    "      print(\"step_loss: {}\".format(step_loss))\n",
    "      \n",
    "def write_batch_input_output_prediction_to_file(train_dir, bucket_num, global_step):\n",
    "  s = \"\"\n",
    "  # inputs\n",
    "  enc_inputs_npa = np.array([list(ar) for ar in encoder_inputs]).T\n",
    "  for sent_id in range(enc_inputs_npa.shape[0]):\n",
    "    sent = enc_inputs_npa[sent_id]\n",
    "    s += \"  \" + str(sent_id) + \": \" + \\\n",
    "         \" \".join(reversed([rev_en_vocab[n].decode(\"utf8\") for n in sent if n != 0])) + \"\\n\"\n",
    "\n",
    "  # outputs\n",
    "  decoder_inputs_npa = np.array([list(ar) for ar in decoder_inputs]).T\n",
    "  for sent_id in range(decoder_inputs_npa.shape[0]):\n",
    "    sent = decoder_inputs_npa[sent_id]\n",
    "    s += \"  \" + str(sent_id) + \": \" + \\\n",
    "         \" \".join([rev_fr_vocab[n].decode(\"utf8\") for n in sent if n != 0]) + \"\\n\"\n",
    "\n",
    "  # predicted outputs\n",
    "  pred_outputs = [list(np.argmax(logit, axis=1)) for logit in output_logits]\n",
    "  pred_outputs = np.array(pred_outputs).T\n",
    "  for sent_id in range(pred_outputs.shape[0]):\n",
    "    sent = pred_outputs[sent_id]\n",
    "    s += \"  \" + str(sent_id) + \": \" + \\\n",
    "         \" \".join([rev_fr_vocab[n].decode(\"utf8\") for n in sent if n != 0]) + \"\\n\"\n",
    "\n",
    "  with open(train_dir + \"batch_trans_\" + str(int(g_step)) + \\\n",
    "       \"_bucket_\" + str(bucket_id) + \".txt\", \"w\") as f:\n",
    "    f.write(s)\n",
    "\n",
    "if do_self_test:\n",
    "  self_test()\n",
    "else:\n",
    "  sess = tf.Session()\n",
    "  \"\"\"Train a en->fr translation model using WMT data.\"\"\"\n",
    "  # Prepare WMT data.\n",
    "  print(\"Preparing WMT data in %s\" % data_dir)\n",
    "  en_train, fr_train, en_dev, fr_dev, _, _ = data_utils.prepare_wmt_data(\n",
    "      data_dir, en_vocab_size, fr_vocab_size)\n",
    "\n",
    "  # Load vocabularies\n",
    "  en_vocab_path = os.path.join(data_dir, \"vocab%d.en\" % en_vocab_size)\n",
    "  fr_vocab_path = os.path.join(data_dir, \"vocab%d.fr\" % fr_vocab_size)\n",
    "  en_vocab, rev_en_vocab = data_utils.initialize_vocabulary(en_vocab_path)\n",
    "  fr_vocab, rev_fr_vocab = data_utils.initialize_vocabulary(fr_vocab_path)\n",
    "\n",
    "  sess = tf.Session()\n",
    "  # Create model.\n",
    "  print(\"Creating %d layers of %d units.\" % (num_layers, size))\n",
    "  model = create_model(sess, False)\n",
    "\n",
    "  # Read data into buckets and compute their sizes.\n",
    "  print (\"Reading development and training data (limit: %d).\"\n",
    "         % max_train_data_size)\n",
    "  dev_set = read_data(en_dev, fr_dev)\n",
    "  train_set = read_data(en_train, fr_train, max_train_data_size)\n",
    "  train_bucket_sizes = [len(train_set[b]) for b in range(len(_buckets))]\n",
    "  train_total_size = float(sum(train_bucket_sizes))\n",
    "\n",
    "  # A bucket scale is a list of increasing numbers from 0 to 1 that we'll use\n",
    "  # to select a bucket. Length of [scale[i], scale[i+1]] is proportional to\n",
    "  # the size if i-th training bucket, as used later.\n",
    "  train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size\n",
    "                         for i in range(len(train_bucket_sizes))]\n",
    "\n",
    "  # This is the training loop.\n",
    "  step_time, loss = 0.0, 0.0\n",
    "  current_step = 0\n",
    "  previous_losses = []\n",
    "  while True:\n",
    "    # Choose a bucket according to data distribution. We pick a random number\n",
    "    # in [0, 1] and use the corresponding interval in train_buckets_scale.\n",
    "    random_number_01 = np.random.random_sample()\n",
    "    bucket_id = min([i for i in range(len(train_buckets_scale))\n",
    "                     if train_buckets_scale[i] > random_number_01])\n",
    "\n",
    "    # Get a batch and make a step.\n",
    "    start_time = time.time()\n",
    "    encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n",
    "        train_set, bucket_id)\n",
    "    _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,\n",
    "                                 target_weights, bucket_id, False)\n",
    "    step_time += (time.time() - start_time) / steps_per_checkpoint\n",
    "    loss += step_loss / steps_per_checkpoint\n",
    "    current_step += 1\n",
    "\n",
    "    # Once in a while, we save checkpoint, print statistics, and run evals.\n",
    "    if True: # current_step % steps_per_checkpoint == 0: ---------------------------------\n",
    "      # Print statistics for the previous epoch.\n",
    "      perplexity = math.exp(float(loss)) if loss < 300 else float(\"inf\")\n",
    "      g_step = sess.run(model.global_step)\n",
    "      with open(train_dir + \"error_log.txt\", \"a\") as f:\n",
    "        f.write(\"train: global step %d learning rate %.4f step-time %.2f perplexity \"\n",
    "             \"%.2f\\n\" % (g_step, sess.run(model.learning_rate), step_time, perplexity))\n",
    "      # Decrease learning rate if no improvement was seen over last 3 times.\n",
    "      if len(previous_losses) > 2 and loss > max(previous_losses[-3:]):\n",
    "        sess.run(model.learning_rate_decay_op)\n",
    "      previous_losses.append(loss)\n",
    "      # Save checkpoint and zero timer and loss.\n",
    "      checkpoint_path = os.path.join(train_dir, \"translate.ckpt\")\n",
    "#       model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "      step_time, loss = 0.0, 0.0\n",
    "      # Run evals on development set and print their perplexity. --------------------------\n",
    "      for bucket_id in range(len(_buckets)):\n",
    "        if len(dev_set[bucket_id]) == 0:\n",
    "          with open(train_dir + \"error_log.txt\", \"a\") as f:\n",
    "            f.write(\"test: empty bucket %d\\n\" % (bucket_id))\n",
    "          continue\n",
    "        encoder_inputs, decoder_inputs, target_weights = model.get_batch(dev_set, bucket_id)\n",
    "        _, eval_loss, output_logits = model.step(sess, encoder_inputs,\n",
    "                                                 decoder_inputs, target_weights, bucket_id, True)\n",
    "        eval_ppx = math.exp(float(eval_loss)) if eval_loss < 300 else float(\"inf\")\n",
    "        with open(train_dir + \"error_log.txt\", \"a\") as f:\n",
    "          f.write(\"test: bucket %d perplexity %.2f\\n\" % (bucket_id, eval_ppx))\n",
    "\n",
    "        # print text example translations\n",
    "        write_batch_input_output_prediction_to_file(train_dir, bucket_id, g_step)\n",
    "        \n",
    "      # print out encoder embeddings as pandas dframe --------------------------------------\n",
    "      for var in tf.trainable_variables():\n",
    "        print(var.name)\n",
    "        if var.name == 'embedding_rnn_seq2seq/RNN/EmbeddingWrapper/embedding:0':\n",
    "            input_embedd_op = var\n",
    "      input_embedd_ar = sess.run(input_embedd_op)\n",
    "      df = pd.DataFrame(data=np_ar, index=[\n",
    "                rev_en_vocab[i].decode(\"utf8\") for i in range(np_ar.shape[0])])\n",
    "      df.head().to_csv(train_dir + \"embedd_df_\" + str(int(g_step)) + \".csv\")\n",
    "      # df.to_csv(train_dir + \"embedd_df_\" + str(int(g_step)) + \".csv\")\n",
    "      \n",
    "      # -------------------------------------------------------------------------------------\n",
    "\n",
    "      # break to capture environment for debug\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
